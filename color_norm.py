import sys
sys.path.append("/data/leuven/373/vsc37341/CLAM")
import os
import argparse
import time
import h5py
import openslide
import numpy as np
from PIL import Image
from tqdm import tqdm

import torch
import torchstain
from torchvision import transforms
from torch.utils.data import DataLoader

from dataset_modules.dataset_h5 import Whole_Slide_Bag_FP
from utils.file_utils import save_hdf5



class TorchstainWithStandardRef:
    def __init__(self, backend='torch'):
        self.device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
        self.normalizer = torchstain.normalizers.MacenkoNormalizer(backend=backend)
        self.normalizer.HERef = self.normalizer.HERef.to(self.device)
        self.normalizer.maxCRef = self.normalizer.maxCRef.to(self.device)
        


        self.T = transforms.Compose([
            transforms.ToTensor(),
            transforms.Lambda(lambda x: x * 255)
        ])
    
    def apply_tensor(self, img_tensor):
        img_tensor = img_tensor.to(self.device)
        #Io = torch.tensor(240.0, device=self.device)  # è¿™è¡Œä»£ç ä¸ç”¨äº†ï¼Œä½†æ˜¯ç•™ç€ä»¥ä½œæé†’ï¼Œæ ‡é‡ä¾‹å¦‚è¿™é‡Œçš„floatä¼šè¢«pytorchè‡ªåŠ¨broadcaståˆ°GPUä¸Š
        #beta = torch.tensor(0.15, device=self.device)  
        #norm, _, _ = self.normalizer.normalize(I=img_tensor, Io=Io, beta=beta, stains=True)
        norm, _, _ = self.normalizer.normalize(I=img_tensor, stains=True)
        # Debug æ‰“å°
        #print("ğŸ¯ DEBUG: img_tensor.device:", img_tensor.device)
        #print("ğŸ¯ DEBUG: HERef.device:", self.normalizer.HERef.device)
        #print("ğŸ¯ DEBUG: Io.device:", Io.device)

        return norm.to("cpu")  # ç¡®ä¿åç»­ numpy è½¬æ¢ä¸ä¼šå‡ºé”™
    
    

def normalize_and_save_patch_features(slide_id, h5_file_path, slide_file_path, output_path, normalizer, batch_size):
    wsi = openslide.open_slide(slide_file_path)
    dataset = Whole_Slide_Bag_FP(file_path=h5_file_path, wsi=wsi, img_transforms=normalizer.T)
    loader = DataLoader(dataset, batch_size=batch_size, num_workers=2, pin_memory=True)

    buffer_imgs = []
    buffer_coords = []
    buffer_size = 100  # å¯è°ƒèŠ‚ï¼š50 æ˜¯ä¸€ä¸ªå®‰å…¨èµ·ç‚¹

    mode = 'w'
    for batch in tqdm(loader, desc=f"å½’ä¸€åŒ–ä¸­: {slide_id}"):
        batch_imgs = batch['img']
        coords = batch['coord'].numpy().astype(np.int32)

        for i in range(len(batch_imgs)):
            try:
                norm_tensor = normalizer.apply_tensor(batch_imgs[i])
                norm_np = norm_tensor.byte().numpy()
            except Exception as e:
                print(f"âŒ å½’ä¸€åŒ–å¤±è´¥ patch: {coords[i]} é”™è¯¯: {e}")
                continue

            buffer_imgs.append(norm_np.reshape(1, *norm_np.shape))
            buffer_coords.append(coords[i].reshape(1, -1))

            # å†™å…¥æ¡ä»¶æ»¡è¶³
            if len(buffer_imgs) >= buffer_size:
                asset_dict = {
                    'color_tensor': np.concatenate(buffer_imgs, axis=0),
                    'coords': np.concatenate(buffer_coords, axis=0)
                }
                save_hdf5(output_path, asset_dict, attr_dict=None, mode=mode)
                mode = 'a'
                buffer_imgs = []
                buffer_coords = []

    # å†™å…¥å‰©ä½™æ²¡å†™çš„ï¼ˆæœ€åä¸€ç»„ < buffer_sizeï¼‰
    if buffer_imgs:
        asset_dict = {
            'color_tensor': np.concatenate(buffer_imgs, axis=0),
            'coords': np.concatenate(buffer_coords, axis=0)
        }
        save_hdf5(output_path, asset_dict, attr_dict=None, mode=mode)



def main(args):
    os.makedirs(args.output_dir, exist_ok=True)
    bags = [f for f in os.listdir(args.data_h5_dir) if f.endswith('.h5')]
    normalizer = TorchstainWithStandardRef()

    if torch.cuda.is_available():
        print("âœ… æ­£åœ¨ä½¿ç”¨ GPU åŠ é€Ÿå½’ä¸€åŒ–å¤„ç†")
    else:
        print("âš ï¸ å½“å‰æœªä½¿ç”¨ GPUï¼Œå¤„ç†å¯èƒ½è¾ƒæ…¢")

    # å‚æ•°æ§åˆ¶
    sleep_every = 10        # æ¯å¤„ç† N å¼  slide
    sleep_seconds = 5       # ä¼‘æ¯ç§’æ•°
    log_path = os.path.join(args.output_dir, "color_norm_log.csv")
    slide_count = 0

    # åˆå§‹åŒ–æ—¥å¿—
    if not os.path.exists(log_path):
        with open(log_path, 'w') as f:
            f.write("slide_id,patch_count,time_sec,status\n")

    for bag_name in bags:
        slide_id = bag_name.split('.h5')[0]
        h5_file_path = os.path.join(args.data_h5_dir, bag_name)
        slide_file_path = os.path.join(args.data_slide_dir, slide_id + args.slide_ext)
        output_path = os.path.join(args.output_dir, bag_name)

        if not os.path.exists(slide_file_path):
            print(f"âŒ slide ä¸å­˜åœ¨: {slide_file_path}")
            continue
        if os.path.exists(output_path):
            print(f"âœ… å·²å­˜åœ¨ï¼Œè·³è¿‡: {slide_id}")
            continue

        print(f"\nğŸ¯ å¤„ç† {slide_id}")
        try:
            start = time.time()
            normalize_and_save_patch_features(slide_id, h5_file_path, slide_file_path, output_path, normalizer, args.batch_size)
            duration = time.time() - start
            status = "OK"
        except Exception as e:
            print(f"âŒ é”™è¯¯: {slide_id} - {e}")
            duration = -1
            status = f"FAIL:{str(e)}"

        # å†™æ—¥å¿—
        patch_count = "?"
        try:
            with h5py.File(output_path, 'r') as f:
                patch_count = f['color_tensor'].shape[0]
        except:
            pass

        with open(log_path, 'a') as f:
            f.write(f"{slide_id},{patch_count},{duration:.2f},{status}\n")

        # æ˜¾å­˜æ¸…ç† + sleep æ§åˆ¶
        torch.cuda.empty_cache()
        slide_count += 1
        if slide_count % sleep_every == 0:
            print(f"ğŸ˜´ å·²å¤„ç† {slide_count} å¼ ï¼Œä¼‘æ¯ {sleep_seconds} ç§’...")
            time.sleep(sleep_seconds)



if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='WSI patch å½’ä¸€åŒ–ä¿å­˜ä¸º HDF5')
    parser.add_argument('--data_h5_dir', type=str, required=True, help='CLAM ç”Ÿæˆçš„ patch åæ ‡ .h5 æ–‡ä»¶ç›®å½•')
    parser.add_argument('--data_slide_dir', type=str, required=True, help='åŸå§‹ WSI æ–‡ä»¶ç›®å½•')
    parser.add_argument('--output_dir', type=str, required=True, help='å½’ä¸€åŒ–å patch ä¿å­˜ç›®å½•')
    parser.add_argument('--slide_ext', type=str, default='.svs', help='WSI æ–‡ä»¶æ‰©å±•å')
    parser.add_argument('--batch_size', type=int, default=1, help='DataLoader æ¯æ‰¹åŠ è½½æ•°é‡')
    args = parser.parse_args()

    main(args)
